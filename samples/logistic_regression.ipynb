{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ebdb38a71da407eb052cd5bc3714a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cf08ad86e9574d54a9429715c1544ace",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_64b0458b41a24a33a149e336f20bef1f",
              "IPY_MODEL_8b1425d84f7145e28b167f88da7f8002"
            ]
          }
        },
        "cf08ad86e9574d54a9429715c1544ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64b0458b41a24a33a149e336f20bef1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9dba76fa891043768657f8a40c711e39",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6e373e2fcdf4ce09803208aa4005ec6"
          }
        },
        "8b1425d84f7145e28b167f88da7f8002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8d08313ec104f17a8c6c997592700c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [11:37&lt;00:00, 332B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd92956cd48b4fc184483dae780c37d0"
          }
        },
        "9dba76fa891043768657f8a40c711e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6e373e2fcdf4ce09803208aa4005ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8d08313ec104f17a8c6c997592700c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd92956cd48b4fc184483dae780c37d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63e62a80cb794905972cce5d1bb1d150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7a02c3da3aca49ada529c688c52b9fbf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be99d75e0a254196b97d12386b229fb2",
              "IPY_MODEL_8e0dec55fa7a4a9bb78696b974ccedc0"
            ]
          }
        },
        "7a02c3da3aca49ada529c688c52b9fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be99d75e0a254196b97d12386b229fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1f570b32d864915af07b8b5725882c1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3493e49edc84a26aefd978803a7eb02"
          }
        },
        "8e0dec55fa7a4a9bb78696b974ccedc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1bd1e9000964bd6a71df9e1a81b5d1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:06&lt;00:00, 65.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f614ca368214b1ab03db8a3e0c13176"
          }
        },
        "e1f570b32d864915af07b8b5725882c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3493e49edc84a26aefd978803a7eb02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1bd1e9000964bd6a71df9e1a81b5d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f614ca368214b1ab03db8a3e0c13176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d59012045aaa4d4aa5c2dc9e7094802f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2b4d78700b14d03a85c32fa084ff3c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_89e80e4b38a84a4c98efd89cb2645730",
              "IPY_MODEL_dbe2efb8a5c94ea5a2c6a7b5a54c5ecb"
            ]
          }
        },
        "a2b4d78700b14d03a85c32fa084ff3c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89e80e4b38a84a4c98efd89cb2645730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_45dd829e054b48858a8ff4322a48a371",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc824c0d4ded49ee9dff16d35f03d220"
          }
        },
        "dbe2efb8a5c94ea5a2c6a7b5a54c5ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b6c2823cddb1491b9e23531d064c99c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 68.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c2ecb2d134e4131a5cb1dc3f0b2a211"
          }
        },
        "45dd829e054b48858a8ff4322a48a371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc824c0d4ded49ee9dff16d35f03d220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6c2823cddb1491b9e23531d064c99c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c2ecb2d134e4131a5cb1dc3f0b2a211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FeOQWTMgh2A",
        "colab_type": "text"
      },
      "source": [
        "For the parts ```Bag of words``` and ```TF-IDF```, I was inspired by the [moocs  of coursera](https://www.coursera.org/learn/language-processing/home/week/1) that I followed recently.  \n",
        "For Bert, I was inspired by the reference [https://www.kaggle.com/rahulvks/distilbert-text-classification](https://www.kaggle.com/rahulvks/distilbert-text-classification) of the document [Technical Resources and Tutorials -- Pascal Notsawo summer 2020 Project 1](https://docs.google.com/document/d/1Sfev84E2mkF5rNNuvtZURlpYAhRw3NLmJqsJ2HQV--I/edit?usp=sharing) (shared drive folder), which itself is a replication of [https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/](https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEvvq1Za-YGd",
        "colab_type": "text"
      },
      "source": [
        "# **Data Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFaQRx5EhskV",
        "colab_type": "text"
      },
      "source": [
        "**Workspace**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuPZeB1Cgz71",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "37eab5fa-de41-4152-cacc-c5c2a989dfa5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm-MS143hM2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp -R /content/drive/\"My Drive\"/\"foo\"/Data /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH1U57g1hxOh",
        "colab_type": "text"
      },
      "source": [
        "**Import necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZxQV4kvhZZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "37719603-3a66-4dd0-bcef-9e560ddf4fc4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pickle\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8C0hG8G0JJp",
        "colab_type": "text"
      },
      "source": [
        "**Import the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPnL4OL0h5Fy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('Data/EULA_Training_Data_Set_1_v1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RnAIz07yo97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f27f619a-3e90-4616-b316-ae8f22bb151b"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7879, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o94SC9SiNxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4169158e-055d-48e5-f31a-d402f23d51cf"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clause ID</th>\n",
              "      <th>Clause Text</th>\n",
              "      <th>Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1588</td>\n",
              "      <td>18. Governing Law: This Agreement shall be gov...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1146</td>\n",
              "      <td>1.8 Modification. We may modify, update, or di...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4792</td>\n",
              "      <td>Except as otherwise expressly provided in this...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2759</td>\n",
              "      <td>8.3.        The benefit and burdens of this Ag...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4400</td>\n",
              "      <td>DEFINITIONS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Clause ID                                        Clause Text  Classification\n",
              "0       1588  18. Governing Law: This Agreement shall be gov...               0\n",
              "1       1146  1.8 Modification. We may modify, update, or di...               1\n",
              "2       4792  Except as otherwise expressly provided in this...               0\n",
              "3       2759  8.3.        The benefit and burdens of this Ag...               1\n",
              "4       4400                                        DEFINITIONS               0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHiR8DmaKxPS",
        "colab_type": "text"
      },
      "source": [
        "**Summary of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ1TmBvn0Xu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0aqX7hy0n1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9f9c2593-1615-48e7-acbe-68632c36332a"
      },
      "source": [
        "df['Classification'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6407\n",
              "1    1472\n",
              "Name: Classification, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN7Fp396kyFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "training_pkl = pickle.load(open(\"Data/train.pkl\", \"rb\"))\n",
        "print(len(training_pkl))\n",
        "for x_y in training_pkl[:5]:\n",
        "  print(\"============\")\n",
        "  print(\"text : \" ,x_y[\"text\"])\n",
        "  print(\"target : \" ,x_y[\"target\"])\n",
        "print(\"============\")\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp_lxOCa1moi",
        "colab_type": "text"
      },
      "source": [
        "# **Spliting the training dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjnuSjRLxdTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = df['Clause Text'].values, df['Classification'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMsvQeU26XSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 1234\n",
        "test_ratio = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY0ccKUC5jU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_ratio, random_state = seed)\n",
        "#X_train, X_test, y_train, y_test = X[:6303], X[6304:], y[:6303], y[6304:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66f76VSUDh7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c152f10-62f6-474d-e419-a019118a06e6"
      },
      "source": [
        "len(X_train), len(X_test),"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6303, 1575)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvSA6tae9gDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "e2f96086-b7ee-469b-f1c0-9a6a7737325e"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'18. Governing Law: This Agreement shall be governed by and interpreted in accordance with the Federal laws of theUnited States, without reference to conflict-of-laws principles. If for any reason a court of competent jurisdiction finds any provision of this Agreement to be unenforceable, that provision will be enforced to the maximum extent possible to effectuate the intent of the parties, and the remainder of this Agreement will continue in full force and effect. This Agreement shall not be governed by the United Nations Convention on Contracts for the International Sale of Goods. Buyer agrees that exclusive jurisdiction for any dispute arising out of or relating to this Agreement lies within the venue mandated by applicable Federal law.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIAWub7U7Usi",
        "colab_type": "text"
      },
      "source": [
        "**Text Prepare**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9mG5ahh7VKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def text_prepare(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower() # lowercase text\n",
        "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = re.sub(BAD_SYMBOLS_RE, '', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join([word for word in text.split() if word not in STOPWORDS]) # delete stopwords from text\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyH8v-FJ7yb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = X_train[0]\n",
        "X_train = [text_prepare(x) for x in X_train]\n",
        "X_test = [text_prepare(x) for x in X_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85ATJDGq74Rt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2e6f83f7-9ebd-4581-8370-0cec5cb71800"
      },
      "source": [
        "print(a)\n",
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18. Governing Law: This Agreement shall be governed by and interpreted in accordance with the Federal laws of theUnited States, without reference to conflict-of-laws principles. If for any reason a court of competent jurisdiction finds any provision of this Agreement to be unenforceable, that provision will be enforced to the maximum extent possible to effectuate the intent of the parties, and the remainder of this Agreement will continue in full force and effect. This Agreement shall not be governed by the United Nations Convention on Contracts for the International Sale of Goods. Buyer agrees that exclusive jurisdiction for any dispute arising out of or relating to this Agreement lies within the venue mandated by applicable Federal law.\n",
            "18 governing law agreement shall governed interpreted accordance federal laws theunited states without reference conflictoflaws principles reason court competent jurisdiction finds provision agreement unenforceable provision enforced maximum extent possible effectuate intent parties remainder agreement continue full force effect agreement shall governed united nations convention contracts international sale goods buyer agrees exclusive jurisdiction dispute arising relating agreement lies within venue mandated applicable federal law\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKtrEzO49Iyj",
        "colab_type": "text"
      },
      "source": [
        "# **Transforming text to a vector**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_KXBgX29i6B",
        "colab_type": "text"
      },
      "source": [
        "## **1) Bag of words**   \n",
        "\n",
        "   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVN1PcNiAgSI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1. Find *N* most popular words in train corpus and numerate them. Now we have a dictionary of the most popular words.\n",
        "2. For each title in the corpora create a zero vector with the dimension equals to *N*.\n",
        "3. For each text in the corpora iterate over words which are in the dictionary and increase by 1 the corresponding coordinate.  \n",
        "\n",
        "Let's try to do it for a toy example. Imagine that we have *N* = 4 and the list of the most popular words is \n",
        "\n",
        "    ['hi', 'you', 'me', 'are']\n",
        "\n",
        "Then we need to numerate them, for example, like this: \n",
        "\n",
        "    {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
        "\n",
        "And we have the text, which we want to transform to the vector:\n",
        "\n",
        "    'hi how are you'\n",
        "\n",
        "For this text we create a corresponding zero vector \n",
        "\n",
        "    [0, 0, 0, 0]\n",
        "    \n",
        "And iterate over all words, and if the word is in the dictionary, we increase the value of the corresponding position in the vector:\n",
        "\n",
        "    'hi':  [1, 0, 0, 0]\n",
        "    'how': [1, 0, 0, 0] # word 'how' is not in our dictionary\n",
        "    'are': [1, 0, 0, 1]\n",
        "    'you': [1, 1, 0, 1]\n",
        "\n",
        "The resulting vector will be \n",
        "\n",
        "    [1, 1, 0, 1]\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQjwERoxAqiT",
        "colab_type": "text"
      },
      "source": [
        "To find the most common words use train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPJlp4WnLWTn",
        "colab_type": "text"
      },
      "source": [
        "**Words counts and most common words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvLzGKs6LaeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_counts = {}\n",
        "for line in X_train:\n",
        "  word_list = line.split()\n",
        "  for word in word_list: \n",
        "    words_counts[word] = words_counts.get(word, 0) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENNsEwfqLeNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c17b386a-72ee-4ddb-e1f8-312ca61edfcb"
      },
      "source": [
        "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "print(most_common_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('company', 8552), ('software', 5066), ('agreement', 5040), ('shall', 3940), ('use', 3493), ('customer', 2941), ('services', 2869), ('may', 2587), ('party', 2280), ('information', 2228)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoavvBFxD_7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DICT_SIZE = 10000 # size of the dictionary\n",
        "WORDS_TO_INDEX = {key: rank for rank, key in enumerate(sorted(words_counts.keys(), key=lambda x: words_counts[x], reverse=True)[:DICT_SIZE], 0)}\n",
        "INDEX_TO_WORDS = {y:x for x,y in WORDS_TO_INDEX.items()}\n",
        "ALL_WORDS = WORDS_TO_INDEX.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twA0zTPVAPlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_bag_of_words(text, words_to_index, dict_size):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        dict_size: size of the dictionary\n",
        "        \n",
        "        return a vector which is a bag-of-words representation of 'text'\n",
        "    \"\"\"\n",
        "    result_vector = np.zeros(dict_size)\n",
        "    for item in text.split():\n",
        "        if item in words_to_index.keys():\n",
        "            result_vector[words_to_index[item]] += 1\n",
        "    return result_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE9NNIBVBPLt",
        "colab_type": "text"
      },
      "source": [
        "Now apply the implemented function to all samples.  \n",
        "We use [scipy.sparse.csr_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) (Compressed Sparse Row matrix) for fast matrix vector products and [scipy.sparse.vstack](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.vstack.html#scipy.sparse.vstack)  to Stack sparse matrices vertically (row wise)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLpV_HCDBEcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sparse matrix package for numeric data.\n",
        "from scipy import sparse as sp_sparse "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSo252G9BHY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
        "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOa0j9DaoM5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "20998ea3-cc29-4d42-c4b6-350ac9453b2f"
      },
      "source": [
        "print('X_train shape ', X_train_mybag.shape)\n",
        "print('X_test shape ', X_test_mybag.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape  (6303, 10000)\n",
            "X_test shape  (1575, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxnxl1wvEgMp",
        "colab_type": "text"
      },
      "source": [
        "## 2) **TF-IDF**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWm8CHowFSgb",
        "colab_type": "text"
      },
      "source": [
        "TF-IDF takes into account total frequencies of words in the corpora. It helps to penalize too frequent words and provide better features space. \n",
        "\n",
        "- We use class [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) from *scikit-learn*. \n",
        "- We use *train* corpus to train a vectorizer. \n",
        "- Our filter out too rare words (occur less than in 5 titles) and too frequent words (occur more than in 90% of the titles)\n",
        "- We use bigrams along with unigrams in our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DUGtA-qGfHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4cKTPq_G7R_",
        "colab_type": "text"
      },
      "source": [
        "How is it work?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bgGwTw_FRDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "b2c48ad3-9b8d-454c-d1d0-bbdc45a7bd83"
      },
      "source": [
        "corpus = [\n",
        "     'This is the first document.',\n",
        "     'This document is the second document.',\n",
        "     'And this is the third one.',\n",
        "     'Is this the first document?',\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_dummy = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.vocabulary_)\n",
        "print(vectorizer.get_feature_names()) \n",
        "print(X_dummy.shape)\n",
        "print(X_dummy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "(4, 9)\n",
            "  (0, 1)\t0.46979138557992045\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 8)\t0.38408524091481483\n",
            "  (1, 5)\t0.5386476208856763\n",
            "  (1, 1)\t0.6876235979836938\n",
            "  (1, 6)\t0.281088674033753\n",
            "  (1, 3)\t0.281088674033753\n",
            "  (1, 8)\t0.281088674033753\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.46979138557992045\n",
            "  (3, 2)\t0.5802858236844359\n",
            "  (3, 6)\t0.38408524091481483\n",
            "  (3, 3)\t0.38408524091481483\n",
            "  (3, 8)\t0.38408524091481483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHxlneWWHet2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf_features(X_train, X_test):\n",
        "    \"\"\"\n",
        "        X_train, X_test — samples        \n",
        "        return TF-IDF vectorized representation of each sample and vocabulary\n",
        "    \"\"\"\n",
        "    # Create TF-IDF vectorizer with a proper parameters choice\n",
        "    # Fit the vectorizer on the train set\n",
        "    # Transform the train and test sets and return the result\n",
        "    \n",
        "    \n",
        "    tfidf_vectorizer = TfidfVectorizer(\n",
        "        lowercase = True, \n",
        "        min_df=5, \n",
        "        max_df=0.9, \n",
        "        ngram_range=(1, 2), \n",
        "        #token_pattern='(\\S+)' # todo\n",
        "    )\n",
        "    \n",
        "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "    X_test = tfidf_vectorizer.transform(X_test)\n",
        "    \n",
        "    return X_train, X_test, tfidf_vectorizer, tfidf_vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVIJYqrjIF1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tfidf, X_test_tfidf, tfidf_vectorizer, tfidf_vocab = tfidf_features(X_train, X_test)\n",
        "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOsvBNyOIxt5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70152fb2-ad3d-451c-f8c5-ec19861cca35"
      },
      "source": [
        "print('X_train_tfidf shape ', X_train_tfidf.shape)\n",
        "print('X_test_tfidf shape ', X_test_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_tfidf shape  (6303, 11638)\n",
            "X_test_tfidf shape  (1575, 11638)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8-S3-r7IPgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "55c80bfd-a97d-4555-e3a3-d7285390db44"
      },
      "source": [
        "assert list(tfidf_vocab.keys())[:10] == list(tfidf_reversed_vocab.values())[:10], \"An error occurred\"\n",
        "list(tfidf_vocab.keys())[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['18',\n",
              " 'governing',\n",
              " 'law',\n",
              " 'agreement',\n",
              " 'shall',\n",
              " 'governed',\n",
              " 'interpreted',\n",
              " 'accordance',\n",
              " 'federal',\n",
              " 'laws']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk3BVtcBTwyj",
        "colab_type": "text"
      },
      "source": [
        "## 3) **BERT**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ-0B3pqPj0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "ded2e2a6-267f-4f38-af2e-79d7ac95b4ab"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 8.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 24.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 54.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=81ddfcfe6bccf3d7373ca45d5e90a8a840cb2bd1431c84fb0d0585fed5bbb895\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QFCqOZ9hCb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import itertools\n",
        "import torch\n",
        "import transformers as tfm\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAGW3vxpPqQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnLXMWA7hMl_",
        "colab_type": "text"
      },
      "source": [
        "**Loading the Pre-trained BERT model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Aljg0nOSNVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "1ebdb38a71da407eb052cd5bc3714a15",
            "cf08ad86e9574d54a9429715c1544ace",
            "64b0458b41a24a33a149e336f20bef1f",
            "8b1425d84f7145e28b167f88da7f8002",
            "9dba76fa891043768657f8a40c711e39",
            "f6e373e2fcdf4ce09803208aa4005ec6",
            "a8d08313ec104f17a8c6c997592700c6",
            "dd92956cd48b4fc184483dae780c37d0",
            "63e62a80cb794905972cce5d1bb1d150",
            "7a02c3da3aca49ada529c688c52b9fbf",
            "be99d75e0a254196b97d12386b229fb2",
            "8e0dec55fa7a4a9bb78696b974ccedc0",
            "e1f570b32d864915af07b8b5725882c1",
            "f3493e49edc84a26aefd978803a7eb02",
            "a1bd1e9000964bd6a71df9e1a81b5d1d",
            "7f614ca368214b1ab03db8a3e0c13176",
            "d59012045aaa4d4aa5c2dc9e7094802f",
            "a2b4d78700b14d03a85c32fa084ff3c6",
            "89e80e4b38a84a4c98efd89cb2645730",
            "dbe2efb8a5c94ea5a2c6a7b5a54c5ecb",
            "45dd829e054b48858a8ff4322a48a371",
            "fc824c0d4ded49ee9dff16d35f03d220",
            "b6c2823cddb1491b9e23531d064c99c5",
            "7c2ecb2d134e4131a5cb1dc3f0b2a211"
          ]
        },
        "outputId": "79e8aa7e-80fc-42c1-cbe5-ee418e3bb535"
      },
      "source": [
        "# For DistilBERT:\n",
        "# model_class, tokenizer_class, pretrained_weights = (tfm.DistilBertModel, tfm.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## For BERT :\n",
        "model_class, tokenizer_class, pretrained_weights = (tfm.BertModel, tfm.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "#max_input_length = tokenizer.max_model_input_sizes['distilbert-base-uncased']\n",
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "\n",
        "model = model_class.from_pretrained(pretrained_weights)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ebdb38a71da407eb052cd5bc3714a15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63e62a80cb794905972cce5d1bb1d150",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d59012045aaa4d4aa5c2dc9e7094802f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8It1tbGRRfup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_and_batching(df, pad_len, batch_size = 32, n_samples = None):\n",
        "    data = []\n",
        "    i = 0 \n",
        "    if n_samples :\n",
        "      n_samples = min(n_samples, df.shape[0])\n",
        "    else :\n",
        "      n_samples = df.shape[0]\n",
        "\n",
        "    ### Tokenization\n",
        "    a = [len(df['Clause Text'][i]) for i in range(100)]\n",
        "    print(a)\n",
        "    tokenized = df['Clause Text'].apply(lambda x : tokenizer.encode(x, add_special_tokens=True))\n",
        "    \n",
        "    ## Padding\n",
        "    padded = pad_sequences(sequences = tokenized, maxlen= pad_len, dtype = 'int64', truncating=\"post\", padding=\"post\")\n",
        "      \n",
        "    ### Batching\n",
        "    input_ids = []\n",
        "    while n_samples > i :\n",
        "        i += batch_size\n",
        "        input_ids.append(torch.LongTensor(padded[i-batch_size:i]).to(device))  \n",
        "    \n",
        "    ## Masking\n",
        "    attention_mask = [np.where(batch.cpu().numpy() != 0, 1, 0) for batch in input_ids]  \n",
        "    attention_mask = [torch.LongTensor(batch).to(device) for batch in attention_mask]\n",
        "    \n",
        "    return input_ids, attention_mask, df['Classification'][:i]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LDYj6zFhsBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids, attention_mask, labels = pad_and_batching(\n",
        "    df = df, \n",
        "    pad_len = max_input_length, # equal to model.config.to_dict()['max_position_embeddings']\n",
        "    batch_size = 32,\n",
        "    n_samples = None\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Easg_hXhxVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(input_ids), input_ids[0].shape)\n",
        "print(len(attention_mask), attention_mask[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJl_NtN-iiCD",
        "colab_type": "text"
      },
      "source": [
        "Model - The model() function runs our sentences through BERT. The results of the processing will be returned into last_hidden_states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFccPG-JikUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_hidden_states = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for input_ids_batch, attention_mask_batch in zip(input_ids, attention_mask) :\n",
        "        last_hidden_states.append(\n",
        "            model(input_ids_batch, attention_mask = attention_mask_batch)\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZkvK-gAiTMr",
        "colab_type": "text"
      },
      "source": [
        "We'll save those in the features variable, as they'll serve as the features to our logitics regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBUkfK-WiHIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten\n",
        "features = list(\n",
        "    itertools.chain.from_iterable(\n",
        "      [batch[0][:,0,:].cpu().numpy() for batch in last_hidden_states]\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWF6mZVjieDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(features, labels, test_size = test_ratio, random_state = seed)\n",
        "#X_train_bert, X_test_bert, y_train_bert, y_test_bert = features[:6303], features[6304:], labels[:6303], labels[6304:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5HTcYzkAGBx",
        "colab_type": "text"
      },
      "source": [
        "**Best parameters search**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdgYGVKWJqCU",
        "colab_type": "text"
      },
      "source": [
        "# **Classifiers**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQDj9tqXQ4ek",
        "colab_type": "text"
      },
      "source": [
        "## **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_hPQU5OKORN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtGOiKveG6AC",
        "colab_type": "text"
      },
      "source": [
        "### **Exhaustive search over specified parameter values for an estimator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q4_V7i6IEr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {'C': np.linspace(start = 0.0001, stop= 100, num=100)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7DpU0QCIW2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search_mybag = GridSearchCV(LogisticRegression(), parameters, n_jobs = -1)\n",
        "grid_search_tfidf = GridSearchCV(LogisticRegression(), parameters, n_jobs = -1)\n",
        "grid_search_bert = GridSearchCV(LogisticRegression(), parameters, n_jobs = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxqgUwtGIpzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search_mybag.fit(X_train_mybag, y_train)\n",
        "grid_search_tfidf.fit(X_train_tfidf, y_train)\n",
        "grid_search_bert.fit(X_train_bert, y_train_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7kWiT2-GkrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d091d646-9e94-4e92-c59f-738353715f23"
      },
      "source": [
        "print('best parameters mybag: ', grid_search_mybag.best_params_)\n",
        "print('best scrores mybag: ', grid_search_mybag.best_score_)\n",
        "\n",
        "print('best parameters tfidf: ', grid_search_tfidf.best_params_)\n",
        "print('best scrores tfidf: ', grid_search_tfidf.best_score_)\n",
        "\n",
        "print('best parameters bert: ', grid_search_bert.best_params_)\n",
        "print('best scrores bert: ', grid_search_bert.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters mybag:  {'C': 1.0102}\n",
            "best scrores mybag:  0.8332507584053974\n",
            "best parameters tfidf:  {'C': 6.0607}\n",
            "best scrores tfidf:  0.8453113553113554\n",
            "best parameters bert:  {'C': 0.0001}\n",
            "best scrores bert:  0.8113597170298201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZHMps8hOE9a",
        "colab_type": "text"
      },
      "source": [
        "Train the classifiers for different data transformations: *bag-of-words*, *tf-idf* and *bert*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUFM8QhmKxiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier_mybag = LogisticRegression(penalty=\"l2\", C=1.0102, solver=\"newton-cg\", random_state = 0, n_jobs = -1).fit(X_train_mybag, y_train)\n",
        "classifier_tfidf = LogisticRegression(penalty=\"l2\", C=6.0607, solver=\"newton-cg\", random_state = 0, n_jobs = -1).fit(X_train_tfidf, y_train)\n",
        "classifier_bert = LogisticRegression(penalty=\"l2\", C=0.0001, solver=\"newton-cg\", random_state = 0, n_jobs = -1).fit(X_train_bert, y_train_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itetoF3cOJDF",
        "colab_type": "text"
      },
      "source": [
        "Create predictions for the data : labels and scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdgM_f_nK12P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_predicted_labels_mybag = classifier_mybag.predict(X_test_mybag)\n",
        "y_test_predicted_scores_mybag = classifier_mybag.decision_function(X_test_mybag)\n",
        "\n",
        "y_test_predicted_labels_tfidf = classifier_tfidf.predict(X_test_tfidf)\n",
        "y_test_predicted_scores_tfidf = classifier_tfidf.decision_function(X_test_tfidf)\n",
        "\n",
        "y_test_predicted_labels_bert = classifier_bert.predict(X_test_bert)\n",
        "y_test_predicted_scores_bert = classifier_bert.decision_function(X_test_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCzbiZkdvjgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fea1e977-4472-4907-e04c-2b90505d3ae7"
      },
      "source": [
        "print('===== Bag-of-words : ', classifier_mybag.score(X_test_mybag, y_test))\n",
        "print('===== Tfidf : ', classifier_tfidf.score(X_test_tfidf, y_test))\n",
        "print('===== Bert : ', classifier_bert.score(X_test_bert, y_test_bert))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Bag-of-words :  0.8533333333333334\n",
            "===== Tfidf :  0.8565079365079366\n",
            "===== Bert :  0.8203174603174603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMuZaV1xOgj0",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "To evaluate the results we will use several classification metrics:\n",
        " - [Accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
        " - [F1-score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOe1RvfIMhnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSOLUDebPAk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_evaluation_scores(y, predicted):\n",
        "    print(\"accuracy_score : \", accuracy_score(y, predicted))\n",
        "    print(\"f1_score : \", f1_score(y, predicted, average=\"macro\"))\n",
        "    print(\"recall_score : \", recall_score(y, predicted, average=\"macro\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVpbDzSFPEcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4e431ca1-bb86-4655-8989-ee81a48d0523"
      },
      "source": [
        "print('===== Bag-of-words')\n",
        "print_evaluation_scores(y_test, y_test_predicted_labels_mybag)\n",
        "print('===== Tfidf')\n",
        "print_evaluation_scores(y_test, y_test_predicted_labels_tfidf)\n",
        "print('===== Bert')\n",
        "print_evaluation_scores(y_test_bert, y_test_predicted_labels_bert)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Bag-of-words\n",
            "accuracy_score :  0.8533333333333334\n",
            "f1_score :  0.728489008590292\n",
            "recall_score :  0.7105345206708311\n",
            "===== Tfidf\n",
            "accuracy_score :  0.8565079365079366\n",
            "f1_score :  0.7143955246873956\n",
            "recall_score :  0.686253541773786\n",
            "===== Bert\n",
            "accuracy_score :  0.8203174603174603\n",
            "f1_score :  0.45064527380537145\n",
            "recall_score :  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErxPGsH1Hm91",
        "colab_type": "text"
      },
      "source": [
        "### **Save for production**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkdBAmViIBx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE8gcfnvH2FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "production = {\n",
        "   \"WORDS_TO_INDEX\" : WORDS_TO_INDEX,\n",
        "   \"DICT_SIZE\" : DICT_SIZE,\n",
        "   \"tfidf_vectorizer\" : tfidf_vectorizer,\n",
        "   \"classifier_mybag\": classifier_mybag,\n",
        "   \"classifier_tfidf\" : classifier_tfidf,\n",
        "   #\"tokenizer\" : tokenizer,\n",
        "   #\"model\" : model,\n",
        "   \"classifier_bert\" : classifier_bert,\n",
        "   \"max_input_length\" : max_input_length\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFGCO-R_IDUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(production, open('/content/production.pth', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5nDMbNNKsoj",
        "colab_type": "text"
      },
      "source": [
        "### **Deploy model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1d9utOjK9eG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "cfbc318b-40b9-4b11-ccc4-45ef2d823f10"
      },
      "source": [
        "! pip install gradio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/42/94dad1613672f0c7047bce471943581a6180275e6b23aff587636c87ee26/gradio-1.0.4-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |████                            | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 440kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 450kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 460kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 471kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 481kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 491kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 501kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 512kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 522kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 532kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 542kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 552kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 563kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 573kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 583kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 593kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 604kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 614kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 624kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 634kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 645kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 655kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 665kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 675kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 686kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 696kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 706kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 716kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 727kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 737kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 747kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 757kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 768kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 778kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 788kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 798kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 808kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 819kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 829kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 839kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 849kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 860kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 870kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 880kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 890kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 901kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 911kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 921kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 931kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 942kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 952kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 962kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 972kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 983kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 993kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 2.7MB/s \n",
            "\u001b[?25hCollecting analytics-python\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/37/c49d052f88655cd96445c36979fb63f69ef859e167eaff5706ca7c8a8ee3/analytics_python-1.2.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from gradio) (0.16.2)\n",
            "Collecting paramiko\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/1e/1e08baaaf6c3d3df1459fd85f0e7d2d6aa916f33958f151ee1ecc9800971/paramiko-2.7.1-py2.py3-none-any.whl (206kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 20.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20kB 17.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 40kB 19.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 51kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 61kB 18.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 81kB 18.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 92kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 102kB 14.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 112kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 122kB 14.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 133kB 14.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 143kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 153kB 14.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 163kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 174kB 14.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 184kB 14.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 194kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 204kB 14.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 14.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gradio) (2.23.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from gradio) (5.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gradio) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gradio) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.6/dist-packages (from analytics-python->gradio) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from analytics-python->gradio) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (2.4)\n",
            "Collecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 17.2MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/1d/82826443777dd4a624e38a08957b975e75df859b381ae302cfd7a30783ed/bcrypt-3.1.7-cp34-abi3-manylinux1_x86_64.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/91/84a29d6a27fd6dfc21f475704c4d2053d58ed7a4033c2b0ce1b4ca4d03d9/cryptography-3.0-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 21.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (2.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (4.3.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (49.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (0.7.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->gradio) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->gradio) (2.4.7)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from pynacl>=1.0.1->paramiko->gradio) (1.14.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->gradio) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->gradio) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->gradio) (0.6.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko->gradio) (2.20)\n",
            "Installing collected packages: analytics-python, pynacl, bcrypt, cryptography, paramiko, gradio\n",
            "Successfully installed analytics-python-1.2.9 bcrypt-3.1.7 cryptography-3.0 gradio-1.0.4 paramiko-2.7.1 pynacl-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxcy7apPLVWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gradio as gr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9tSnqTLXv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mybag_predict(eula):\n",
        "    vec = my_bag_of_words(text_prepare(eula) , WORDS_TO_INDEX, DICT_SIZE)\n",
        "    output = classifier_mybag.predict([vec])[0]\n",
        "    return \"EULA acceptable\" if output == 1 else \"EULA unacceptable\"\n",
        "\n",
        "def tfidf_predict(eula):\n",
        "    vec = tfidf_vectorizer.transform([text_prepare(eula)])\n",
        "    output = classifier_tfidf.predict(vec)[0]\n",
        "    return \"EULA acceptable\" if output == 1 else \"EULA unacceptable\"\n",
        "\n",
        "def bert_predict(eula):\n",
        "  tokens = tokenizer.tokenize(eula)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  init_token_idx = tokenizer.cls_token_id\n",
        "  eos_token_idx = tokenizer.sep_token_id\n",
        "  indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  with torch.no_grad():\n",
        "        pooled_output, _ = model(tensor)\n",
        "  vec = pooled_output[:,0,:].cpu().numpy()\n",
        "  output = classifier_bert.predict(vec)[0]\n",
        "  return \"EULA acceptable\" if output == 1 else \"EULA unacceptable\"\n",
        "\n",
        "def predict(model_name, eula):\n",
        "  if model_name == \"Bag of word\":\n",
        "    return mybag_predict(eula)\n",
        "  elif model_name == \"TD-IDF\":\n",
        "    return tfidf_predict(eula)\n",
        "  elif model_name == \"BERT\":\n",
        "    return bert_predict(eula)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijgkud5PikJx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_TRVcECLf39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = gr.inputs.Textbox(placeholder=\"Your end-user license agreements\", label = \"EULA\", lines=20)\n",
        "output = gr.outputs.Textbox()\n",
        "gr.Interface(fn = mybag_predict, inputs = inputs, outputs = output).launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QluOp4_Fiy3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = gr.inputs.Textbox(placeholder=\"Your end-user license agreements\", label = \"EULA\", lines=20)\n",
        "output = gr.outputs.Textbox()\n",
        "gr.Interface(fn = tfidf_predict, inputs = inputs, outputs = output).launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r1WkANt2IFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = gr.inputs.Textbox(placeholder=\"Your end-user license agreements\", label = \"EULA\", lines=20)\n",
        "output = gr.outputs.Textbox()\n",
        "gr.Interface(fn = bert_predict, inputs = inputs, outputs = output).launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjkHV3rp4LrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = gr.inputs.Textbox(placeholder=\"Your end-user license agreements\", label = \"EULA\", lines=20)\n",
        "output = gr.outputs.Textbox()\n",
        "gr.Interface(fn = bert_predict, inputs = inputs, outputs = output).launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzIEBU2K6_pt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "5d9e10a3-a70b-4947-bf33-d06561ede4f2"
      },
      "source": [
        "inputs = gr.inputs.Textbox(placeholder=\"Your end-user license agreements\", label = \"EULA\", lines=20)\n",
        "model_name = gr.inputs.Dropdown([\"Bag of word\", \"TD-IDF\", \"BERT\"], label = \"model name\")\n",
        "output = gr.outputs.Textbox()\n",
        "gr.Interface(fn = predict, inputs = [model_name, inputs], outputs = output).launch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on External URL: https://14360.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://14360.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f8898c26dd8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.networking.serve_files_in_background.<locals>.HTTPServer at 0x7f8926ead278>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://14360.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p4IAhOd_wdX",
        "colab_type": "text"
      },
      "source": [
        "## **Gaussian Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svfDbQHL_6QS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0f17b1a-3823-451f-ba43-cae5080b1c79"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb = gnb.fit(X_train_bert, y_train_bert)\n",
        "\n",
        "gnb.score(X_test_bert,  y_test_bert)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.753015873015873"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    }
  ]
}